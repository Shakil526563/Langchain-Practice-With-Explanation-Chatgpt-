{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNnMEWJsMjzZ1jH6QtAj72"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WS1XbfJYaoTv"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["рждрзБржорж┐ ржЬрж╛ржирждрзЗ ржЪрж╛ржЪрзНржЫрзЛ:\n","`MultiQueryRetriever` ржПржмржВ `ContextualCompressionRetriever` ржХржЦржи ржУ ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯ тАФ Bangla ржПржмржВ English ржжрзБржЯрзЛ ржнрж╛рж╖рж╛рзЯред\n","\n","ржирж┐ржЪрзЗ ржкрзВрж░рзНржг ржмрзНржпрж╛ржЦрзНржпрж╛ тЬЕ output ржзрж╛рж░ржгрж╛рж╕рж╣ ржжрзЗржУрзЯрж╛ рж╣рж▓рзЛ:\n","\n","---\n","\n","## тЬЕ `from langchain.retrievers.multi_query import MultiQueryRetriever`\n","\n","ЁЯФ╣ **ЁЯЗзЁЯЗй ржХржЦржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржм**:\n","ржпржЦржи рждрзБржорж┐ ржЪрж╛ржУ рждрзЛржорж╛рж░ ржПржХржЯрж┐ ржкрзНрж░рж╢рзНржиржХрзЗ LLM ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ **multiple diverse queries**-ржП рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рждрзЗ ржПржмржВ ржЖрж░ржУ ржнрж╛рж▓ relevant ржбржХрзБржорзЗржирзНржЯ ржЖржирждрзЗред\n","\n","ЁЯФ╣ **ЁЯЗмЁЯЗз When to use**:\n","Use this when you want to **expand one user query into several variations** using LLM, and retrieve broader/more accurate results.\n","\n","ЁЯза **Use Case**:\n","\n","* ржкрзНрж░рж╢рзНржи ржЕржирзЗржХ vague/general рж╣рж▓рзЗ\n","* Similar context ржерж╛ржХрж╛ рж╕рждрзНрждрзНржмрзЗржУ relevant data ржирж╛ ржЖрж╕рж▓рзЗ\n","* Better Recall (more documents)\n","\n","ЁЯУМ **Example**:\n","\n","```python\n","from langchain.retrievers.multi_query import MultiQueryRetriever\n","from langchain.chat_models import ChatOpenAI\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.docstore.document import Document\n","\n","# Sample vector store\n","docs = [\n","    Document(page_content=\"LangChain supports agents, chains, and tools.\"),\n","    Document(page_content=\"You can use OpenAI or HuggingFace models with LangChain.\"),\n","    Document(page_content=\"Vector stores like FAISS and Pinecone are used in RAG.\"),\n","]\n","\n","embedding = OpenAIEmbeddings()\n","vectordb = FAISS.from_documents(docs, embedding)\n","\n","# LLM for query expansion\n","llm = ChatOpenAI(temperature=0)\n","\n","retriever = MultiQueryRetriever.from_llm(\n","    retriever=vectordb.as_retriever(), llm=llm\n",")\n","\n","results = retriever.get_relevant_documents(\"How does LangChain use models?\")\n","\n","print(\"\\nЁЯУМ MultiQueryRetriever Output:\")\n","for i, doc in enumerate(results):\n","    print(f\"{i+1}. {doc.page_content}\")\n","```\n","\n","**тЬЕ Output:**\n","\n","```\n","ЁЯУМ MultiQueryRetriever Output:\n","1. LangChain supports agents, chains, and tools.\n","2. You can use OpenAI or HuggingFace models with LangChain.\n","```\n","\n","---\n","\n","## тЬЕ `from langchain.retrievers import ContextualCompressionRetriever`\n","\n","ЁЯФ╣ **ЁЯЗзЁЯЗй ржХржЦржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржм**:\n","ржпржЦржи рждрзБржорж┐ ржЪрж╛ржУ retrieved documents ржЧрзБрж▓рзЛржХрзЗ **LLM ржжрж┐рзЯрзЗ рж╕ржВржХрзБржЪрж┐ржд (compress)** ржХрж░рзЗ ржХрзЗржмрж▓ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржЕржВрж╢ retain ржХрж░рждрзЗред\n","\n","ЁЯФ╣ **ЁЯЗмЁЯЗз When to use**:\n","Use this when you want to **compress or summarize** the retrieved documents before passing them to your LLM тАФ to **reduce token usage** and focus only on relevant content.\n","\n","ЁЯза **Use Case**:\n","\n","* Long documents (PDFs, full pages)\n","* Token budget рж╕рзАржорж┐ржд\n","* Want to filter noise and get just the core context\n","\n","ЁЯУМ **Example**:\n","\n","```python\n","from langchain.retrievers import ContextualCompressionRetriever\n","from langchain.retrievers.document_compressors import LLMChainExtractor\n","from langchain.chat_models import ChatOpenAI\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.docstore.document import Document\n","\n","# Sample vector DB\n","docs = [\n","    Document(page_content=\"LangChain has many modules such as agents and chains.\"),\n","    Document(page_content=\"The embedding size for OpenAI models is 1536.\"),\n","]\n","\n","embedding = OpenAIEmbeddings()\n","vectordb = FAISS.from_documents(docs, embedding)\n","\n","# Compressor\n","llm = ChatOpenAI(temperature=0)\n","compressor = LLMChainExtractor.from_llm(llm)\n","\n","# Wrap with compressor\n","retriever = ContextualCompressionRetriever(\n","    base_compressor=compressor,\n","    base_retriever=vectordb.as_retriever()\n",")\n","\n","# Query\n","results = retriever.get_relevant_documents(\"What is LangChain?\")\n","\n","print(\"\\nЁЯУМ ContextualCompressionRetriever Output:\")\n","for i, doc in enumerate(results):\n","    print(f\"{i+1}. {doc.page_content}\")\n","```\n","\n","**тЬЕ Output (Compressed Example):**\n","\n","```\n","ЁЯУМ ContextualCompressionRetriever Output:\n","1. LangChain has modules like agents and chains.\n","```\n","\n","---\n","\n","## ЁЯза Summary Table\n","\n","| Retriever                        | When to Use                                             | Benefit                            |\n","| -------------------------------- | ------------------------------------------------------- | ---------------------------------- |\n","| `MultiQueryRetriever`            | ржПржХ ржкрзНрж░рж╢рзНржиржХрзЗ ржмрж┐ржнрж┐ржирзНржи рж░рзВржкрзЗ expand ржХрж░рждрзЗ                    | Better **recall**, broader match   |\n","| `ContextualCompressionRetriever` | Retrieved docs ржерзЗржХрзЗ relevant ржЕржВрж╢ retain ржХрж░рждрзЗ (LLM ржжрж┐рзЯрзЗ) | Lower **tokens**, better precision |\n","\n","---\n","\n","ЁЯзк **Want a combo?**\n","рждрзБржорж┐ ржЪрж╛ржЗрж▓рзЗ `MultiQueryRetriever` + `ContextualCompressionRetriever` ржПржХрж╕рж╛ржерзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рждрзЗ ржкрж╛рж░рзЛ for **Smart + Compressed Retrieval**.\n","\n","ржмрж▓рж▓рзЗ ржЖржорж┐ full pipeline example ржжрж┐рзЯрзЗ ржжрзЗржм!\n","\n","Would you like that? тЬЕ\n"],"metadata":{"id":"aYkKuSbbmXKh"}}]}