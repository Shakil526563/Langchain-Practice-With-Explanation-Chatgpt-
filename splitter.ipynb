{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeFJvTLdR1km8dVDupJ7fy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bGaaKBa3qFIR"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["рждрзБржорж┐ ржЬрж╛ржирждрзЗ ржЪрж╛ржЪрзНржЫрзЛ:\n","LangChain-ржП `TokenTextSplitter`, `RecursiveCharacterTextSplitter`, ржПржмржВ `CharacterTextSplitter` ржХржЦржи ржУ ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯред\n","\n","ржирж┐ржЪрзЗ **Bangla + English** ржорж┐рж▓рж┐рзЯрзЗ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд ржмрзНржпрж╛ржЦрзНржпрж╛ ржжрж┐рж▓рж╛ржо тАФ\n","\n","---\n","\n","## тЬЕ `from langchain.text_splitter import TokenTextSplitter`\n","\n","ЁЯФ╣ **ЁЯЗзЁЯЗй ржХржЦржи ржУ ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржм**:\n","ржпржЦржи рждрзБржорж┐ **token count ржЕржирзБржпрж╛рзЯрзА** ржЯрзЗржХрзНрж╕ржЯ ржнрж╛ржЧ ржХрж░рждрзЗ ржЪрж╛ржУ (GPT models ржпрзЗржоржи GPT-3/4 ржпрзЗржЦрж╛ржирзЗ token limit ржЖржЫрзЗ)ред\n","\n","ЁЯФ╣ **ЁЯЗмЁЯЗз When & Why to Use**:\n","Use this to split text based on **number of tokens**, not characters. Helps avoid exceeding LLM token limits.\n","\n","ЁЯза **Use case**:\n","\n","* Token-efficient chunking\n","* Preparing documents for embedding or LLMs\n","* Keeping each chunk under model limits (e.g., 512 or 2048 tokens)\n","\n","ЁЯУМ **Example**:\n","\n","```python\n","from langchain.text_splitter import TokenTextSplitter\n","\n","splitter = TokenTextSplitter(chunk_size=200, chunk_overlap=20)\n","chunks = splitter.split_text(\"Your long document text goes here...\")\n","```\n","\n","---\n","\n","## тЬЕ `from langchain.text_splitter import RecursiveCharacterTextSplitter`\n","\n","ЁЯФ╣ **ЁЯЗзЁЯЗй ржХржЦржи ржУ ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржм**:\n","ржпржЦржи ржЪрж╛ржЗржЫрзЛ ржЯрзЗржХрзНрж╕ржЯ **ржЧржаржиржорзВрж▓ржХржнрж╛ржмрзЗ ржмрж┐ржнржХрзНржд** рж╣рзЛржХтАФ ржкрзНрж░ржержорзЗ ржмрзЬ unit (ржкрзНржпрж╛рж░рж╛), рждрж╛рж░ржкрж░ ржЫрзЛржЯ unit (рж▓рж╛ржЗржи, рж╢ржмрзНржж) тАФ ржпрж╛рждрзЗ рждржерзНржпрзЗрж░ continuity ржмржЬрж╛рзЯ ржерж╛ржХрзЗред\n","\n","ЁЯФ╣ **ЁЯЗмЁЯЗз When & Why to Use**:\n","Use for **intelligent splitting** тАФ it tries to split on logical boundaries (e.g., paragraphs, sentences), and only breaks mid-text if necessary.\n","\n","ЁЯза **Use case**:\n","\n","* Document QA / RAG (Retrieval-Augmented Generation)\n","* Chatbot with multi-paragraph understanding\n","* Text with structure (articles, blog posts)\n","\n","ЁЯУМ **Example**:\n","\n","```python\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","chunks = splitter.split_text(\"A long article or story...\")\n","```\n","\n","---\n","\n","## тЬЕ `from langchain.text_splitter import CharacterTextSplitter`\n","\n","ЁЯФ╣ **ЁЯЗзЁЯЗй ржХржЦржи ржУ ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржм**:\n","ржпржжрж┐ ржЦрзБржм рж╕рзЛржЬрж╛ ржнрж╛ржмрзЗ рж╢рзБржзрзБ **character count** ржЕржирзБржпрж╛рзЯрзА ржЯрзЗржХрзНрж╕ржЯ ржнрж╛ржЧ ржХрж░рждрзЗ ржЪрж╛ржУред ржПржЯрж╛ ржХрзЛржирзЛ structure ржзрж░рзЗ ржирж╛ред\n","\n","ЁЯФ╣ **ЁЯЗмЁЯЗз When & Why to Use**:\n","Use when you want to split text **strictly by character length**, with no regard for sentence/paragraph breaks.\n","\n","ЁЯза **Use case**:\n","\n","* Very simple chunking\n","* Pre-processing when structure isnтАЩt important\n","\n","ЁЯУМ **Example**:\n","\n","```python\n","from langchain.text_splitter import CharacterTextSplitter\n","\n","splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=30)\n","chunks = splitter.split_text(\"Line1\\nLine2\\nLine3\\n...\")\n","```\n","\n","---\n","\n","## ЁЯза Summary Table\n","\n","| TextSplitter Class               | ЁЯЗзЁЯЗй ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи ржпржЦржи...                  | ЁЯЗмЁЯЗз Use When...                    | Best For...                        |\n","| -------------------------------- | ----------------------------------------- | ----------------------------------- | ---------------------------------- |\n","| `TokenTextSplitter`              | ржЯрзЛржХрзЗржи рж╕ржВржЦрзНржпрж╛рж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ ржнрж╛ржЧ ржХрж░рждрзЗ ржЪрж╛ржи | You want to split by token count    | GPT token-safe chunking            |\n","| `RecursiveCharacterTextSplitter` | рж╕рзНржорж╛рж░рзНржЯ/ржЧржаржиржорзВрж▓ржХржнрж╛ржмрзЗ ржнрж╛ржЧ ржжрж░ржХрж╛рж░             | You want smart, recursive splitting | RAG, multi-paragraph understanding |\n","| `CharacterTextSplitter`          | character count ржЕржирзБржпрж╛рзЯрзА рж╕рзЛржЬрж╛ ржнрж╛ржЧ ржжрж░ржХрж╛рж░    | Basic splitting by character length | Simple pre-processing              |\n","\n","---\n","\n","ЁЯФЪ **рж╢рзЗрж╖ ржХржерж╛ (Final Note)**\n","Text Splitter ржмрзНржпржмрж╣рж╛рж░ ржирж╛ ржХрж░рж▓рзЗ ржмрзЬ ржбржХрзБржорзЗржирзНржЯ GPT ржмрж╛ LLM context limit-ржП ржврзБржХржмрзЗ ржирж╛ред\n","ЁЯСЙ рждрж╛ржЗ VectorStore, QA, ржмрж╛ Chunk-based Memory pipeline ржмрж╛ржирж╛рждрзЗ ржПржЧрзБрж▓рзЛ **ржЦрзБржм ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг**ред\n","\n","ЁЯФз ржЪрж╛ржЗрж▓рзЗ ржЖржорж┐ ржПржХржЯрж╛ ржЫрзЛржЯ **TextSplitter + Document QA pipeline** ржмрж╛ржирж┐рзЯрзЗ ржжрж┐рждрзЗ ржкрж╛рж░рж┐ред\n","\n","**Would you like a full example using these text splitters for document retrieval or QA?**\n"],"metadata":{"id":"dVbcmmpFqHhw"}}]}